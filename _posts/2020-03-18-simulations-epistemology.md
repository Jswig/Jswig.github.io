---
title: "Computer simulations and epistemology"
date: 2018-03-15
categories:
  - essays
tags:
  - epistemology
  - philosophy
---

Karl Popper, ontology and the validity of computer simulations as an empirical tool

---
Since the Manhattan project in the 1940s, computer simulations are a core tool of scientific investigation, particularly in fields  in which carrying out physical experiments is impractical if not impossible, from as nuclear detonations to geological history. 
In 2010, ‘Bolshoi’, a massive simulation of the evolution of the universe was run on NASA’s Pleiades supercomputer, producing a model universe surprisingly similar to our own, supporting the current model of galaxy formation (Hayes, 2012). In this instance, the computer simulations enabled scientists to study a problem which is otherwise difficult, both due to its scale - the 8 billion particles over 400,000 time frames involved in this “simplified” model are orders of magnitude more than what any human can keep track of - and its subject - the evolution of the universe over the last 13 billion years is not readily available to observation. 
However, while computer simulations are of great use in studying complex scientific problems, they appear to raise several novel epistemological problems for science.  For instance the ‘virtual’ aspect of computer simulations raises the question of whether they can provide knowledge of the ‘real’ objects science claims to study . 
{: .text-justify}

I adopt in what follows the definition of a computer simulation as a computational device that produces, by a temporal process, solutions to a computational model which correctly represents a system or process (Grüne-Yanoff, Weirich, 2010, pp. 23).
I will attempt to address here whether computer simulations raise new epistemological issues in science, while suggesting potential answers to these issues.
{: .text-justify}

#### Ontology of simulations
It has be argued that computer simulations, as a result of their ontological nature, i.e. of the category of objects they deal with, are epistemologically inferior to other tools of scientific investigation, particularly physical experiments.  
{: .text-justify}

Following this argument, on one hand there are computer simulations, which only have a formal relation to the real-world object of interest: the mathematical model underlying the simulation only theoretically describes it. The simulation thus deals with abstract or conceptual things which would not belong to the same category of things as physical objects. (Grüne-Yanoff, Weirich, 2010, pp. 27). On the other hand, physical experiments and observations  have a direct relation to the object as their target is the object of interest itself, i.e. both share “the same stuff” (Grüne-Yanoff, Weirich ,2010, pp. 27).
{: .text-justify}

Computer simulations’  claim to epistemological validity would thus be far weaker: the experimenter knows that the causes at work in a physical experiment are the same as those being targeted,  while a computer simulation depends on abstract causes which are different from the physical causes being targeted. 
{: .text-justify}

However, this ontological distinction between computer simulations on one side and physical observation on the other is less clear-cut that it first appears. Vallverdú argues that in the case of physical experiments “(...) we are not talking about real things but about concepts that we think that capture those things. In this sense the representation of the reality is ontologically-dependant of our tools, not about the reality itself.” (2014, pp. 8). In other words, both physical experiments and computer simulations are mediated by the conceptual tools we use. Science deals with the physical world through the lens of a theoretical framework. 
{: .text-justify}

Latour, in *We Have Never Been Modern* demonstrates this with the example of Boyle’s pump. Some of Boyle’s contemporaries’  “ideas about matter” had them ascribe the observed phenomena in the former's experiment to properties of ‘ether’ (1993, pp 13-24). Boyle, however, by rejecting the theory of ‘ether’, was able to observe that he had indeed created a partial vacuum. Thus, what is observed in physical experiments is mediated by the conceptual tools in use.  
{: .text-justify}

It would then make little sense to draw an ontological distinction between computer simulations  and physical observation, as in both cases the scientist is first and foremost dealing with concepts by the theory, i.e. abstract things. To return to the example of the ‘Bolshoi’ computer simulation, the results of both the simulation and the physical observation of the cosmos were mediated by the same conceptual tools: Newtonian dynamics, models of galaxy formation, models for dark matter. 
Therefore, if we were to question the epistemological validity of simulations based on ontological arguments, we would have to question the validity of  abstract models. Of course, as such models are a feature of scientific reasoning in general, such an issue would hardly be particular or new to computer simulations. 
{: .text-justify}

#### ‘Epistemological opacity’ of simulations

I have made the argument that computer simulations do not appear *a priori* more epistemologically problematic than other scientific tools. However, many have pointed out that practical implementation raises new issues. 
{: .text-justify}

Simulations are useful in that they allow able scientists to explores problems which are otherwise difficult to study experimentally- galaxy formation, nuclear detonations, global climate. However, this advantage simultaneously raises new issues. In practice, the complexity and quantity of calculations performed many  modern simulations far outreaches anything a human would be capable of reproducing. For instance, the ‘Bolshoi’ simulation featured over 8 billion particles over 400,000 time units (Hayes, 2012) - orders of magnitude more than a human scientist can keep track of, let alone perform calculations on. Simulations thus become “black boxes” in which scientists input and retrieve data, without being able to fully grasp the steps in between (Grüne-Yanoff, Weirich, 2010, pp. 33-34). In other words, the processes taking place in modern-day simulations are almost incommensurable to human cognition. 
{: .text-justify}

Furthermore, computer simulations are often characterized by their emergent properties, i.e. properties which only appear as result of running the simulation, without apparently any necessary connection to the model used to build the simulation. A well known example of emergence is Conway’s Game of Life, an simulation featuring an extremely simple model - a two-dimensional grid of cells and a single rule governing the transformation of cells from white to black - yet in which extremely complex patterns emerge, even if they do not seems to  logicallyfollow from the model (Grüne-Yanoff, Weirich, 2010, pp. 34). Explaining how these patterns emerge becomes very difficult for the scientist given the issue of computational complexity outlined above.
{: .text-justify}

Simulations are thus epistemologically “opaque” (Humphreys, 2009, pp. 619) in that no can understand the entire process by which a simulation produces a result due to both their inherent and emergent complexity. Essentially, a solution may produce a valid result, but the scientist will be hard-pressed to explain the how or why of such a result.
{: .text-justify}

Thus, computer simulations lend themselves poorly to the inference of explanations from their results. In other words, as the characteristics of simulations obfuscate the process by which they produce results, it becomes  difficult to infer gain understanding of the object being studied and thus formulate  scientific hypotheses about it (Grüne-Yanoff, Weirich, 2010, pp. 26). Simulations would  appear to lose their epistemological usefulness if they cannot provide means of corroborating scientific hypotheses.     
{: .text-justify}

#### Simulation as a means of falsification

The above criticism of the usefulness relies on an inductive view of science, that is, that the epistemological validity of a scientific theory is determined by the process by which the theory was constructed. As a simulation obfuscates the explanations of its results, it cannot serve as a justification in the construction of a scientific theory. 
{: .text-justify}

However, I will argue that this issue may be avoided if we adopt an alternative criteria for testing the epistemological validity of scientific theories, as formulated by Karl Popper in his *Logic of Scientific Discovery* : scientific theories are valid only insofar as they both lends himself to, and resist, falsification (1959, pp. 30). For instance, if I formulate the hypothesis that “All swans are white”, no matter how many times I see a white swan, I will not never be certain that all swans are indeed white. However, if I observe one black swan, I can successfully demonstrate that my hypothesis is incorrect and thus falsified my hypothesis (Popper, 1959, pp. 27). In other words, the only way by which we can arrive at a decisive judgement concerning the validity of a scientific hypothesis is by supplying an invalidating counter-example.
{: .text-justify}

Therefore, by this criteria of falsification, computer simulations allow the scientist to make the same sort of claims about the epistemological validity of a scientific hypothesis as any other means of scientific investigation, namely invaliding claims which falsify a hypothesis. To clarify,  just as a physical experiment, a computer simulation may yield results which contradict a scientific theory, which would then force the scientist to reevaluate the said theory.  For instance, the ‘Bolshoi’ simulation produced satellite galaxies with a frequency matching the one predicted by observational data, meaning that the current hypothesis concerning their frequency was not unvalidated.  However, the simulations yielded dwarf galaxies at a rate far exceeding observational data, pointing to an issue in the model used in the simulation, prompting the researchers to refine the model (Hayes, 2012).
{: .text-justify}

The lack of explanatory power I outlined in the previous section is thus unproblematic for the epistemological value of simulations, as by the criteria of falsification only the results of simulations would be needed to test the validity of a hypothesis. It must be pointed  out however that in pratice, computer simulations rarely alone invalidate a scientific hypothesis. Often, as in our example of the ‘Bolshoi’ simulations, the results of a simulation are be cross-compared with other sources of data to before a hypothesis is definitely considered invalidated.
{: .text-justify}

##### In conclusion

The ontological essence of computer simulations does not seem to raise any epistemological issues which are not already present in the mathematical models - which were already ubiquitous in science - underlying them, i.e. any epistemological issue raised by the ontological nature of computer simulations would not be particular to these but would rather apply to science in general. Furthermore, I argued that  while the “explanatory opacity” of computer simulations limits them as a basis for the inductive inference of scientific hypotheses, this characteristic is not very problematic epistemologically if we adopt falsifiability as the criteria of epistemological  validity. Therefore, computer simulations would not lead to any significant new epistemological issues. However, I concede that computer simulations are of limited use if not conjoined with other tools of scientific investigation, and therefore cannot alone serve as foundations for new scientific knowledge.
{: .text-justify}

#### References
[1] Grüne-Yanoff, T., Weirich, T. (2010). The philosophy and epistemology of simulation: a review. 
Simulation & Gaming 41(1), 20 –50. DOI: 10.1177/1046878109353470

[2] Hayes, B. (January 2012). A box of universe. American Scientist 100(1), 10. 
https://www.americanscientist.org/article/a-box-of-universe

[3] Humphreys, P. (2009).  The philosophical novelty of computer simulation. Synthese, 169(3). 
 615–626. DOI: 10.1007/s11229-008-9435-2

[4] Latour, B. (1993) Constitution. We Have Never Been Modern (pp. 13-24) Cambridge: Harvard 
University Press. 

[5] Popper, K. (1959). Introduction to the logic of science. The Logic of Scientific Discovery (pp. 
27-56). London: Routledge Classics.

[6] Vallverdú, J. (2014). What are simulations? An epistemological approach. Procedia Technology, 
13,  6-15.  http://www.sciencedirect.com/science/article/pii/S2212017314000139

